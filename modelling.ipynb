{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2245f785",
   "metadata": {},
   "source": [
    "## Modelling & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0fb33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46b8a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned dataset\n",
    "df=pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "\n",
    "#Selecting target and features from the dataframe\n",
    "target_cols = ['coupon', 'expiration']\n",
    "X = df.drop(columns=target_cols)\n",
    "y = df[target_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "095b143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['destination', 'passenger', 'weather', 'time', 'gender', 'age', 'maritalStatus', 'education', 'occupation', 'income', 'Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50', 'age_group']\n",
      "Numerical: ['temperature', 'has_children', 'toCoupon_GEQ5min', 'toCoupon_GEQ15min', 'toCoupon_GEQ25min', 'direction_same', 'direction_opp', 'Y']\n"
     ]
    }
   ],
   "source": [
    "#automatically separate columns by dtype\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "print(\"Categorical:\", categorical_cols)\n",
    "print(\"Numerical:\", numerical_cols)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82ba9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y['coupon']  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946e3df",
   "metadata": {},
   "source": [
    "### Processing\n",
    "A preprocessing pipeline was created, where numeric columns underwent median imputation and standardization (StandardScaler), while categorical columns were processed using imputation and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e59571b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical and categorical features\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78ba9d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;temperature&#x27;,\n",
       "                                                   &#x27;has_children&#x27;,\n",
       "                                                   &#x27;toCoupon_GEQ5min&#x27;,\n",
       "                                                   &#x27;toCoupon_GEQ15min&#x27;,\n",
       "                                                   &#x27;toCoupon_GEQ25min&#x27;,\n",
       "                                                   &#x27;direction_same&#x27;,\n",
       "                                                   &#x27;direction_opp&#x27;, &#x27;Y&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;destination&#x27;, &#x27;passenger&#x27;,\n",
       "                                                   &#x27;weather&#x27;, &#x27;time&#x27;, &#x27;gender&#x27;,\n",
       "                                                   &#x27;age&#x27;, &#x27;maritalStatus&#x27;,\n",
       "                                                   &#x27;education&#x27;, &#x27;occupation&#x27;,\n",
       "                                                   &#x27;income&#x27;, &#x27;Bar&#x27;,\n",
       "                                                   &#x27;CoffeeHouse&#x27;, &#x27;CarryAway&#x27;,\n",
       "                                                   &#x27;RestaurantLessThan20&#x27;,\n",
       "                                                   &#x27;Restaurant20To50&#x27;,\n",
       "                                                   &#x27;age_group&#x27;])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;temperature&#x27;,\n",
       "                                                   &#x27;has_children&#x27;,\n",
       "                                                   &#x27;toCoupon_GEQ5min&#x27;,\n",
       "                                                   &#x27;toCoupon_GEQ15min&#x27;,\n",
       "                                                   &#x27;toCoupon_GEQ25min&#x27;,\n",
       "                                                   &#x27;direction_same&#x27;,\n",
       "                                                   &#x27;direction_opp&#x27;, &#x27;Y&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;destination&#x27;, &#x27;passenger&#x27;,\n",
       "                                                   &#x27;weather&#x27;, &#x27;time&#x27;, &#x27;gender&#x27;,\n",
       "                                                   &#x27;age&#x27;, &#x27;maritalStatus&#x27;,\n",
       "                                                   &#x27;education&#x27;, &#x27;occupation&#x27;,\n",
       "                                                   &#x27;income&#x27;, &#x27;Bar&#x27;,\n",
       "                                                   &#x27;CoffeeHouse&#x27;, &#x27;CarryAway&#x27;,\n",
       "                                                   &#x27;RestaurantLessThan20&#x27;,\n",
       "                                                   &#x27;Restaurant20To50&#x27;,\n",
       "                                                   &#x27;age_group&#x27;])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;temperature&#x27;, &#x27;has_children&#x27;,\n",
       "                                  &#x27;toCoupon_GEQ5min&#x27;, &#x27;toCoupon_GEQ15min&#x27;,\n",
       "                                  &#x27;toCoupon_GEQ25min&#x27;, &#x27;direction_same&#x27;,\n",
       "                                  &#x27;direction_opp&#x27;, &#x27;Y&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;destination&#x27;, &#x27;passenger&#x27;, &#x27;weather&#x27;, &#x27;time&#x27;,\n",
       "                                  &#x27;gender&#x27;, &#x27;age&#x27;, &#x27;maritalStatus&#x27;, &#x27;education&#x27;,\n",
       "                                  &#x27;occupation&#x27;, &#x27;income&#x27;, &#x27;Bar&#x27;, &#x27;CoffeeHouse&#x27;,\n",
       "                                  &#x27;CarryAway&#x27;, &#x27;RestaurantLessThan20&#x27;,\n",
       "                                  &#x27;Restaurant20To50&#x27;, &#x27;age_group&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;temperature&#x27;, &#x27;has_children&#x27;, &#x27;toCoupon_GEQ5min&#x27;, &#x27;toCoupon_GEQ15min&#x27;, &#x27;toCoupon_GEQ25min&#x27;, &#x27;direction_same&#x27;, &#x27;direction_opp&#x27;, &#x27;Y&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;destination&#x27;, &#x27;passenger&#x27;, &#x27;weather&#x27;, &#x27;time&#x27;, &#x27;gender&#x27;, &#x27;age&#x27;, &#x27;maritalStatus&#x27;, &#x27;education&#x27;, &#x27;occupation&#x27;, &#x27;income&#x27;, &#x27;Bar&#x27;, &#x27;CoffeeHouse&#x27;, &#x27;CarryAway&#x27;, &#x27;RestaurantLessThan20&#x27;, &#x27;Restaurant20To50&#x27;, &#x27;age_group&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['temperature',\n",
       "                                                   'has_children',\n",
       "                                                   'toCoupon_GEQ5min',\n",
       "                                                   'toCoupon_GEQ15min',\n",
       "                                                   'toCoupon_GEQ25min',\n",
       "                                                   'direction_same',\n",
       "                                                   'direction_opp', 'Y']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['destination', 'passenger',\n",
       "                                                   'weather', 'time', 'gender',\n",
       "                                                   'age', 'maritalStatus',\n",
       "                                                   'education', 'occupation',\n",
       "                                                   'income', 'Bar',\n",
       "                                                   'CoffeeHouse', 'CarryAway',\n",
       "                                                   'RestaurantLessThan20',\n",
       "                                                   'Restaurant20To50',\n",
       "                                                   'age_group'])])),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=LogisticRegression(max_iter=1000)))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building pipeline\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', MultiOutputClassifier(logreg))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bde7b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Coupon:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  Bar       0.42      0.37      0.40       402\n",
      "Carry out & Take away       0.44      0.41      0.42       469\n",
      "         Coffee House       0.42      0.59      0.49       798\n",
      "    Restaurant(20-50)       0.55      0.25      0.35       297\n",
      "      Restaurant(<20)       0.41      0.36      0.39       556\n",
      "\n",
      "             accuracy                           0.43      2522\n",
      "            macro avg       0.45      0.40      0.41      2522\n",
      "         weighted avg       0.44      0.43      0.42      2522\n",
      "\n",
      "\n",
      "Classification Report for Expiration:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1d       0.63      0.71      0.67      1392\n",
      "          2h       0.57      0.48      0.52      1130\n",
      "\n",
      "    accuracy                           0.61      2522\n",
      "   macro avg       0.60      0.59      0.59      2522\n",
      "weighted avg       0.60      0.61      0.60      2522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report for Coupon:\\n\")\n",
    "print(classification_report(y_test['coupon'], y_pred[:,0]))\n",
    "\n",
    "print(\"\\nClassification Report for Expiration:\\n\")\n",
    "print(classification_report(y_test['expiration'], y_pred[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77040bf",
   "metadata": {},
   "source": [
    "Observation and recommendation\n",
    "**Coupon**\n",
    "* Overall accuracy is 43%, which is only slightly better than random guessing for a 5-class problem.\n",
    "* The Coffee House class has the highest recall (0.58) — the model is relatively better at identifying this class, though precision remains low.\n",
    "* The Restaurant(20-50) class has particularly low recall (0.25), meaning the model misses most of these instances.\n",
    "* The F1-scores for all classes are below 0.50, indicating poor balance between precision & recall.\n",
    "* Weighted average F1-score: 0.42\n",
    "\n",
    "**Expiration**\n",
    "* Overall accuracy is 61%, better than the coupon task.\n",
    "* The model performs better on the 1d class, with higher recall and F1.\n",
    "* The 2h class has lower precision & recall, meaning the model struggles to identify it correctly.\n",
    "* Weighted F1-score: 0.60\n",
    "\n",
    "**Recommendations**\n",
    "* Address potential class imbalance in the targets.\n",
    "* Perform feature engineering, such as grouping rare categories\n",
    "* Experiment with advanced models (e.g., Random Forest, Gradient Boosting) and tune hyperparameters.\n",
    "* Use cross-validation for more robust evaluation and avoid overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5bd10d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target: coupon \n",
      "Detected 5 classes for target: coupon\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.726\n",
      "Confusion Matrix:\n",
      "[[284   6  74   9  29]\n",
      " [  5 346  74   9  35]\n",
      " [ 59  40 624  14  61]\n",
      " [ 10   4  52 182  49]\n",
      " [ 26  42  79  15 394]]\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  Bar       0.74      0.71      0.72       402\n",
      "Carry out & Take away       0.79      0.74      0.76       469\n",
      "         Coffee House       0.69      0.78      0.73       798\n",
      "    Restaurant(20-50)       0.79      0.61      0.69       297\n",
      "      Restaurant(<20)       0.69      0.71      0.70       556\n",
      "\n",
      "             accuracy                           0.73      2522\n",
      "            macro avg       0.74      0.71      0.72      2522\n",
      "         weighted avg       0.73      0.73      0.73      2522\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "[14:48:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Accuracy: 0.756\n",
      "Confusion Matrix:\n",
      "[[289   3  57  23  30]\n",
      " [  6 386  46   2  29]\n",
      " [ 47  44 633  17  57]\n",
      " [ 10   8  35 204  40]\n",
      " [ 33  41  73  14 395]]\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  Bar       0.75      0.72      0.73       402\n",
      "Carry out & Take away       0.80      0.82      0.81       469\n",
      "         Coffee House       0.75      0.79      0.77       798\n",
      "    Restaurant(20-50)       0.78      0.69      0.73       297\n",
      "      Restaurant(<20)       0.72      0.71      0.71       556\n",
      "\n",
      "             accuracy                           0.76      2522\n",
      "            macro avg       0.76      0.75      0.75      2522\n",
      "         weighted avg       0.76      0.76      0.76      2522\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 228\n",
      "[LightGBM] [Info] Number of data points in the train set: 10088, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.836355\n",
      "[LightGBM] [Info] Start training from score -1.682738\n",
      "[LightGBM] [Info] Start training from score -1.151012\n",
      "[LightGBM] [Info] Start training from score -2.136553\n",
      "[LightGBM] [Info] Start training from score -1.512489\n",
      "Accuracy: 0.772\n",
      "Confusion Matrix:\n",
      "[[302   2  53  20  25]\n",
      " [  9 392  46   1  21]\n",
      " [ 46  39 648  14  51]\n",
      " [ 10   7  40 200  40]\n",
      " [ 36  38  67   9 406]]\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  Bar       0.75      0.75      0.75       402\n",
      "Carry out & Take away       0.82      0.84      0.83       469\n",
      "         Coffee House       0.76      0.81      0.78       798\n",
      "    Restaurant(20-50)       0.82      0.67      0.74       297\n",
      "      Restaurant(<20)       0.75      0.73      0.74       556\n",
      "\n",
      "             accuracy                           0.77      2522\n",
      "            macro avg       0.78      0.76      0.77      2522\n",
      "         weighted avg       0.77      0.77      0.77      2522\n",
      "\n",
      "\n",
      "Target: expiration \n",
      "Detected 2 classes for target: expiration\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.693\n",
      "Confusion Matrix:\n",
      "[[1012  380]\n",
      " [ 394  736]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1d       0.72      0.73      0.72      1392\n",
      "          2h       0.66      0.65      0.66      1130\n",
      "\n",
      "    accuracy                           0.69      2522\n",
      "   macro avg       0.69      0.69      0.69      2522\n",
      "weighted avg       0.69      0.69      0.69      2522\n",
      "\n",
      "\n",
      "Model: XGBoost\n",
      "[14:48:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Accuracy: 0.751\n",
      "Confusion Matrix:\n",
      "[[1058  334]\n",
      " [ 294  836]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1d       0.78      0.76      0.77      1392\n",
      "          2h       0.71      0.74      0.73      1130\n",
      "\n",
      "    accuracy                           0.75      2522\n",
      "   macro avg       0.75      0.75      0.75      2522\n",
      "weighted avg       0.75      0.75      0.75      2522\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 228\n",
      "[LightGBM] [Info] Number of data points in the train set: 10088, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -0.581640\n",
      "[LightGBM] [Info] Start training from score -0.818667\n",
      "Accuracy: 0.768\n",
      "Confusion Matrix:\n",
      "[[1077  315]\n",
      " [ 269  861]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1d       0.80      0.77      0.79      1392\n",
      "          2h       0.73      0.76      0.75      1130\n",
      "\n",
      "    accuracy                           0.77      2522\n",
      "   macro avg       0.77      0.77      0.77      2522\n",
      "weighted avg       0.77      0.77      0.77      2522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the models \n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': None,  \n",
    "    'LightGBM': None\n",
    "}\n",
    "\n",
    "target_cols = ['coupon', 'expiration']\n",
    "\n",
    "for target in target_cols:\n",
    "    print(f\"\\nTarget: {target} \")\n",
    "    n_classes = len(np.unique(y_train[target]))\n",
    "    print(f\"Detected {n_classes} classes for target: {target}\")\n",
    "    \n",
    "    # re-define models with correct params for multi-class\n",
    "    models['XGBoost'] = XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=n_classes,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42\n",
    "    )\n",
    "    models['LightGBM'] = LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        num_class=n_classes,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nModel: {name}\")\n",
    "\n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),   \n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        # Train\n",
    "        pipeline.fit(X_train, y_train[target])\n",
    "\n",
    "        # Predict\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluate\n",
    "        acc = accuracy_score(y_test[target], y_pred)\n",
    "        print(f\"Accuracy: {acc:.3f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test[target], y_pred))\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test[target], y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e4ac23",
   "metadata": {},
   "source": [
    "#### General Observation \n",
    "All advanced models outperform Logistic Regression, which had 69% accuracy and lower recall/F1-scores.\n",
    "\n",
    "All three models (Random Forest, XGBoost, LightGBM) perform well and consistently, with LightGBM slightly outperforming the others.\n",
    "Best accuracy: 77% (LightGBM)\n",
    "\n",
    "Class imbalance still affects class 0 — all models have lower recall on class 0, meaning many 0s are wrongly predicted as 1s.\n",
    "\n",
    "Class 1 (majority) is predicted well across all models (recall 82%).37\n",
    "weighted avg       0.74      0.74      0.74      2537\n",
    "\n",
    "\n",
    "**Recommendations**\n",
    "Proceed to LightGB as the preferred model for deployment or further tuning.\n",
    "\n",
    "Investigate classes with lower recall (like Restaurant(20-50) and Bar) — possibly due to underrepresentation or overlapping features.\n",
    "\n",
    "If desired, explore hyperparameter tuning or feature engineering to improve the weaker classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af40a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check distribution of coupon classes\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(y=df['coupon'], order=df['coupon'].value_counts().index)\n",
    "plt.title(\"Class Distribution: Coupon\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Coupon Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a0ea1f",
   "metadata": {},
   "source": [
    " We'll use SMOTE (Synthetic Minority Oversampling Technique) to handle the rare classes (e.g., Restaurant(20-50) and Bar) in your coupon target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5e018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      " Coffee House             3191\n",
      "Restaurant(<20)          2223\n",
      "Carry out & Take away    1875\n",
      "Bar                      1608\n",
      "Restaurant(20-50)        1191\n",
      "Name: coupon, dtype: int64\n",
      "Encoded X_train shape: (10088, 111)\n",
      "\n",
      "After SMOTE class distribution:\n",
      " Restaurant(<20)          3191\n",
      "Bar                      3191\n",
      "Coffee House             3191\n",
      "Restaurant(20-50)        3191\n",
      "Carry out & Take away    3191\n",
      "Name: coupon, dtype: int64\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22016\n",
      "[LightGBM] [Info] Number of data points in the train set: 15955, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "\n",
      "Accuracy: 0.775\n",
      "\n",
      "Confusion Matrix:\n",
      " [[313   1  46  17  25]\n",
      " [  8 399  42   1  19]\n",
      " [ 52  43 638  17  48]\n",
      " [ 11   8  39 202  37]\n",
      " [ 36  38  67  12 403]]\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                  Bar       0.75      0.78      0.76       402\n",
      "Carry out & Take away       0.82      0.85      0.83       469\n",
      "         Coffee House       0.77      0.80      0.78       798\n",
      "    Restaurant(20-50)       0.81      0.68      0.74       297\n",
      "      Restaurant(<20)       0.76      0.72      0.74       556\n",
      "\n",
      "             accuracy                           0.78      2522\n",
      "            macro avg       0.78      0.77      0.77      2522\n",
      "         weighted avg       0.78      0.78      0.77      2522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# assume df is your cleaned DataFrame\n",
    "X = df.drop(columns=['coupon', 'expiration'])\n",
    "y = df[['coupon', 'expiration']]   # both targets\n",
    "\n",
    "# Work on coupon first\n",
    "target = 'coupon'\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y[target], test_size=0.2, random_state=42, stratify=y[target]\n",
    ")\n",
    "\n",
    "print(\"Original class distribution:\\n\", y_train.value_counts())\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = X_train.select_dtypes(include='object').columns\n",
    "numerical_cols = X_train.select_dtypes(exclude='object').columns\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', 'passthrough', numerical_cols)\n",
    "])\n",
    "\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Encoded X_train shape: {X_train_encoded.shape}\")\n",
    "\n",
    "# Apply SMOTE on encoded data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "print(\"\\nAfter SMOTE class distribution:\\n\", pd.Series(y_train_sm).value_counts())\n",
    "\n",
    "# Train LightGBM on SMOTE data\n",
    "model = LGBMClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27052c14",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8cda2150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21867\n",
      "[LightGBM] [Info] Number of data points in the train set: 10636, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609062\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19367\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10022\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21867\n",
      "[LightGBM] [Info] Number of data points in the train set: 10636, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609062\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19367\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10022\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21867\n",
      "[LightGBM] [Info] Number of data points in the train set: 10636, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609062\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19367\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10022\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21867\n",
      "[LightGBM] [Info] Number of data points in the train set: 10636, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609062\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19367\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10022\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21867\n",
      "[LightGBM] [Info] Number of data points in the train set: 10636, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609062\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19367\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10022\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21867\n",
      "[LightGBM] [Info] Number of data points in the train set: 10636, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609062\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19367\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10022\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21867\n",
      "[LightGBM] [Info] Number of data points in the train set: 10636, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609062\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19367\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10022\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21867\n",
      "[LightGBM] [Info] Number of data points in the train set: 10636, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609062\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Start training from score -1.609532\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19367\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10022\n",
      "[LightGBM] [Info] Number of data points in the train set: 10637, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609626\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Start training from score -1.609156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22016\n",
      "[LightGBM] [Info] Number of data points in the train set: 15955, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "Best params: {'learning_rate': 0.1, 'n_estimators': 200, 'num_leaves': 50}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(LGBMClassifier(random_state=42), param_grid, cv=3)\n",
    "grid.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8eb9de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f305976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a4fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
